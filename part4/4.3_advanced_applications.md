# 3.3. Advanced CNN Applications: Object Detection & Segmentation

## 1. Introduction: Beyond Image Classification

While classic CNNs excel at image classification (assigning a single label to an entire image), many real-world computer vision tasks require a more detailed understanding of an image's content. Object detection and semantic segmentation are two such tasks that take us from "what is in this image?" to "what is in this image, and where is it?". These advanced applications build upon the powerful feature extraction capabilities of CNNs.

*   **Object Detection:** The goal is to identify and locate all objects of certain classes within an image. The output is a set of bounding boxes, each with an associated class label and a confidence score.
*   **Semantic Segmentation:** The goal is to assign a class label to every single pixel in an image. The output is a "mask" or a "segmentation map" of the same size as the input image.

---

## 2. Object Detection

Object detection models typically have two main components: a **backbone** network and a **detection head**.

*   **Backbone:** A standard pre-trained CNN (like ResNet) that acts as a powerful feature extractor.
*   **Detection Head:** A network that takes the features from the backbone and predicts the bounding boxes and class labels.

There are two main families of object detection models:

### 2.1. Two-Stage Detectors (e.g., R-CNN Family)

These models break the problem down into two stages.

1.  **Region Proposal:** A Region Proposal Network (RPN) scans the image and proposes a set of candidate regions ("regions of interest") where objects are likely to be located.
2.  **Classification and Refinement:** For each proposed region, the model extracts features (using a technique like RoI Pooling or RoI Align) and then uses a second network to classify the object and refine the bounding box.

*   **Models:** R-CNN, Fast R-CNN, Faster R-CNN.
*   **Pros:** Generally have higher accuracy.
*   **Cons:** Slower, as they involve multiple steps.
*   **Interview Insight:** Faster R-CNN was a major breakthrough because it integrated the region proposal step into the main network, making the whole process end-to-end trainable and much faster than its predecessors.

### 2.2. One-Stage Detectors (e.g., YOLO, SSD)

These models treat object detection as a single regression problem. They predict the bounding boxes and class probabilities directly from the full image in a single pass.

*   **How they work:** The image is divided into a grid. For each grid cell, the model predicts a set of bounding boxes, confidence scores for those boxes, and class probabilities.
*   **Models:** YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector).
*   **Pros:** Much faster, often capable of running in real-time.
*   **Cons:** Historically, they have been slightly less accurate than two-stage detectors, although this gap has narrowed significantly.
*   **Interview Insight:** YOLO was a game-changer for real-time object detection. Discussing the tradeoff between the accuracy of two-stage detectors and the speed of one-stage detectors is a key point.

---

## 3. Semantic Segmentation

Semantic segmentation models also use a backbone CNN for feature extraction, but their architecture is typically an **encoder-decoder** structure.

*   **Encoder:** This is the standard CNN backbone (e.g., ResNet). As the data passes through the encoder, the spatial dimensions of the feature maps are progressively reduced (downsampling) through pooling or strided convolutions. This allows the network to learn high-level semantic features.
*   **Decoder:** The decoder's job is to take these low-resolution, high-level features and gradually **upsample** them back to the original image resolution. The output is a segmentation map where each pixel has a class label.

**Key Architectural Concepts:**

*   **Upsampling:** The process of increasing the spatial resolution of a feature map. Common techniques include:
    *   **Transposed Convolution (or Deconvolution):** A learnable upsampling layer.
    *   **Simple Upsampling (e.g., bilinear interpolation) followed by a standard convolution.**
*   **Skip Connections:** A crucial innovation, popularized by the **U-Net** architecture. Skip connections feed the output of encoder layers directly to the corresponding layers in the decoder. This allows the decoder to use both the high-level semantic information from the deep layers and the fine-grained spatial information from the early layers. This is essential for producing accurate segmentation boundaries.

**Interview Insight:** The U-Net architecture is the canonical example of an encoder-decoder network for segmentation. Its symmetric, U-shaped architecture and its heavy use of skip connections are its defining features. Understanding why skip connections are so important (they combine "what" with "where" information) is key.